{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a3d954c-f19f-4fa0-836c-cce0fc58d87f",
   "metadata": {},
   "source": [
    "## Introduction to Markov Chains for Beginners\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a6d004-3e19-4917-8812-85fa1a4ee8b5",
   "metadata": {},
   "source": [
    "### What is a Markov Chain?\n",
    "\n",
    "A Markov Chain is a simple way to predict the probability of something happening based on a current situation. It's like guessing what comes next based on what's happening now, without worrying about what happened before.\n",
    "\n",
    "### Basic Concepts\n",
    "States: These are the possible situations or events. In our case, each word in a sentence is a state. <br>\n",
    "Transitions: The process of moving from one state to another. For example, moving from the word \"the\" to \"cat\".\n",
    "\n",
    "### Example\n",
    "Consider these sentences:\n",
    "\n",
    "\"the cat sat on the mat\" <br>\n",
    "\"the cat is on the mat\" <br>\n",
    "\"the cat is named Bob\" <br>\n",
    "\n",
    "From these, we can make some simple predictions, like:<br>\n",
    "After \"the\", the word \"cat\" is most likely to come next. Every time we see \"the\", it's followed by \"cat\". So, we say the chance (probability) of \"cat\" coming after \"the\" is 100% or 1.\n",
    "\n",
    "### A Simple Python Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0f4c64-b000-47bf-b696-4736ffeb181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98245c4-5a1f-4e3e-ac6f-2d9689709941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_markov_chain(data):\n",
    "    markov_chain = {}\n",
    "    for sentence in data: #loop through each sentence in the data\n",
    "        sentence = sentence.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "        words = sentence.split()  #split sentence into words\n",
    "        for i in range(len(words) - 1):\n",
    "            word = words[i]  #Create pairs of consecutive words\n",
    "            next_word = words[i + 1]\n",
    "            if word in markov_chain:\n",
    "                if next_word in markov_chain[word]:\n",
    "                    markov_chain[word][next_word] += 1 #update the markov_chain dictionary with these pairs\n",
    "                else:\n",
    "                    markov_chain[word][next_word] = 1 #update the markov_chain dictionary with these pairs\n",
    "            else:\n",
    "                markov_chain[word] = {next_word: 1} #update the markov_chain dictionary with these pairs\n",
    "\n",
    "    # Convert counts to probabilities\n",
    "    for word, next_words in markov_chain.items():\n",
    "        total_count = sum(next_words.values())\n",
    "        markov_chain[word] = {key: value / total_count for key, value in next_words.items()}\n",
    "\n",
    "    return markov_chain #each key is a word and each value is a dictionary of successor words with their corresponding probability of following the key word.\n",
    "\n",
    "def generate_sentence(chain, start_word, length=5): #This function generates a sentence using the Markov Chain.\n",
    "    if start_word not in chain:\n",
    "        return \"Start word not in dataset. Please try a different word.\"\n",
    "\n",
    "    word = start_word\n",
    "    sentence = [word]\n",
    "    for _ in range(length - 1):\n",
    "        next_words = chain.get(word, None) #look up the next possible words in the chain and their probabilities. \n",
    "        if not next_words:\n",
    "            break\n",
    "        word = random.choices(list(next_words.keys()), weights=next_words.values())[0] #selects an item from the list, with the probability of selecting each item being proportional to its corresponding weight. \n",
    "        sentence.append(word)\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271cf6b9-0071-46ed-8fc1-1cc0f56b45ef",
   "metadata": {},
   "source": [
    "### Try It Yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95eec0fa-aac5-4526-ae3e-df3178fa6209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat is named\n"
     ]
    }
   ],
   "source": [
    "data = [\"the cat sat on the mat.\",\"the cat is on the mat\",\"the cat is named Bob\"] #input your data\n",
    "chain = build_markov_chain(data)\n",
    "\n",
    "start_word = \"cat\"  #input your chosen word\n",
    "length_sentence = 3 #input the length of your sentence\n",
    "sentence = generate_sentence(chain, start_word, length_sentence)\n",
    "print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25faafcb-e8ec-4a68-8c56-24233ad04c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': {'cat': 0.6, 'mat': 0.4},\n",
       " 'cat': {'sat': 0.3333333333333333, 'is': 0.6666666666666666},\n",
       " 'sat': {'on': 1.0},\n",
       " 'on': {'the': 1.0},\n",
       " 'is': {'on': 0.5, 'named': 0.5},\n",
       " 'named': {'bob': 1.0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at the probabilities\n",
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc6e5d5-c32e-494c-91bb-38d07c423207",
   "metadata": {},
   "source": [
    "### Some Limitations\n",
    "- Memorylessness (Lack of History Dependence): One of the fundamental assumptions of a Markov chain is that the future state depends only on the current state and not on the sequence of events that led to it. In many real-world scenarios, however, past states or the history of a process can significantly influence future outcomes. Therefore, this limitation can lead to oversimplification in modeling complex systems where history plays a crucial role. <br>\n",
    "- State Space Complexity: For systems with a large number of potential states, the Markov chain model can become extremely complex and computationally demanding, making it difficult to analyze and draw meaningful conclusions.<br>\n",
    "- Stationarity Assumption: Many Markov Chain models are built on the assumption of stationarity, meaning that the transition probabilities are constant over time. However, this assumption does not hold true in dynamic systems where these probabilities may change due to evolving external factors or internal dynamics of the system. Non-stationary behavior in real-world processes can lead to significant inaccuracies in predictions and analyses based on standard Markov Chain models.\n",
    "\n",
    "### Conclusion\n",
    "Markov Chains are a fun and easy way to get started with predicting things based on current information. They show us how we can use simple rules to make guesses about what might happen next!\n",
    "\n",
    "-------\n",
    "\n",
    "This version aims to be more beginner-friendly, explaining Markov Chains in simple terms and using easy-to-understand examples. Itâ€™s perfect for starters who are just getting into the concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f48621-3433-4881-88c9-b38b14e62172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpp",
   "language": "python",
   "name": "tpp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
